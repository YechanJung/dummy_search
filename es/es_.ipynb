{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "spark = SparkSession.builder.appName(\"indexer\").config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## docker run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker pull docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n",
    "# docker pull docker.elastic.co/kibana/kibana:8.15.0\n",
    "\n",
    "# docker run -d --name elasticsearch --net elastic -p 9200:9200 -p 9300:9300 -m 1GB -e \"discovery.type=single-node\" -e \"ELASTIC_PASSWORD=password\" -e \"xpack.security.enabled=false\" -e \"xpack.security.enrollment.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.15.0\n",
    "# docker run -d --name kibana --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.15.0\n",
    "# ! docker pull apache/kafka:3.8.0\n",
    "\n",
    "# ! docker run -d --name kafka -p 9092:9092 apache/kafka:3.8.0\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
